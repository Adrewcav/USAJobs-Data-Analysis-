---
title: "Data Jobs in the U.S. Government"
author: "Andrew Cavalier"
date: "11/24/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Overview

Project and its relevant files are on **[Github](https://github.com/Adrewcav/API-Data-Collection-)!**

The goal of this project is to answer the business question: How to become a Data Analyst in the U.S. government?
Therefore, this document showcases the key requirements and metrics for data-related job fields with the U.S. Government. The data used in this project is collated from the USAJobs.gov API and Office of Personnel Management (OPM). **The project is broken down into the following steps**

### Step 1: Extract Data from API
For this project, live data was extracted (or Requested) using API calls looking for **key search terms** with the USAJobs.gov Rest API. This process was useful for collecting large amounts of live data from a reliable, publicly available source. The drawback with this data however, is that it needs to be cleaned.

Key Search Terms: 

* Scientist
* Data
* Analyst
* Data Scientist 

The results of the data extraction with these key words is the creation of 4 separate data sets that will be cleaned for analysis later on. 

**Note**, it is common for agencies to define data job duties and their job titles differently even if they are technically the same job per the Job Description (i.e. "Computer Scientist" and "Data Scientist"). The different naming conventions sometimes reflect the specialization or scope of the position within the Data Science field, however they also frequently do not. Therefore, assumptions are made that the data may not reflect all position titles or currently available positions that the U.S. government has on offer for the Data Science Field. 

### Step 2: Extract Data frame to Excel File

A **write_xlsx** command was utilized to extract the data frame for each data set into excel files. The Excel files hold the data from each data frame made with an API call and are represented by the names **Scientist**, **Data**, **Analyst**, and **Data Scientist**.

The raw data is combined into an excel spreadsheet and is stored **[here](https://github.com/Adrewcav/USAJobs-Data-Analysis-/blob/main/Combined%20Data%20Raw%20.xlsx)**. 


### Step 3: Clean Data
Clean data in Excel:

* **1.** All data was copied from seperate Excel files into a single Excel file, with different sheets names for the corresponding data. 

* **2.** Before cleaning the data, I tried to make sense of the data and determine which data is relevant to the question.

* **3.** Create a new sheet titled **"Combined"** to house the relevant data from the other sheets for cleaning and analysis.

* **4** Label relevant column titles (i.e. "MatchedObjectDescriptor.PositionTitle" -> "Position Title") and remove unneeded data columns.

* **5.** Remove Duplicate data. Select all data (cmd+A) -> Data -> Remove Duplicates -> select only Column A. **Note**, this was the purpose of retaining the Match ID values as they represent a unique identity for a job posting and wouldn't remove data for having the same job title. 

* **6.** Create binary variables for certain data points.
The following variables are used for the data point **Minimum Degree Level**: Bachelor's, Master's, Phd, or N/A. 
The other data points, **Python**, **R**, **SQL**, and **Tableau** have the variables TRUE or FALSE. 

**Note**, There is a challenge for step 6 with this data set, since data such as minimum degree level or key skills for a position, are not listed in binary terms. This data is present in 1-2 columns with a 1-300 word description per row item. Therefore, before we can introduce this data in binary terms with our dataset, we will need to perform a separate analysis i.e. analyzing word frequency and word count. This will allow us to determine if a position mentions a term in the description. 

### Step 4: Visualize Data 
* Take data and create visuals. Automate if possible. 

### Step 5: Insights Overview
**Key Insight Metrics:**

* Position Title 
* Organization/Agency 
* Location
* Telework Eligible 
* Grade Levels
* **Qualifications Summary**
* Minimum Degree Level
* Skills: Python, R, SQL, Tableau

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.



